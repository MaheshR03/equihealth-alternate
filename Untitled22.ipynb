{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/21Bhoomika05/main/blob/main/Untitled22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from imblearn.combine import SMOTEENN\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/drive/MyDrive/health_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Drop irrelevant columns\n",
        "df = df.drop(['id', 'State Names', 'District'], axis=1)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Target (Healthcare Access)', axis=1)\n",
        "y = df['Target (Healthcare Access)']\n",
        "\n",
        "# Balance classes using SMOTE-ENN\n",
        "smote_enn = SMOTEENN(random_state=42)\n",
        "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_resampled)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_resampled, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Define the XGBoost model\n",
        "xgb = XGBClassifier(objective='multi:softmax', num_class=5, random_state=42)\n",
        "\n",
        "# Define hyperparameter grid for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Hyperparameter tuning with RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    xgb, param_distributions=param_dist, n_iter=20,\n",
        "    scoring='accuracy', cv=5, random_state=42, n_jobs=-1, verbose=1\n",
        ")\n",
        "\n",
        "# Fit the model with training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Use the best estimator from the search\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Save the trained model and scaler\n",
        "joblib.dump(best_model, 'xgb_best_model.pkl')\n",
        "joblib.dump(scaler, 'xgb_scaler.pkl')\n",
        "\n",
        "# Load the saved model and scaler for predictions\n",
        "loaded_model = joblib.load('xgb_best_model.pkl')\n",
        "loaded_scaler = joblib.load('xgb_scaler.pkl')\n",
        "\n",
        "# Example: Predict with new data input (15 features)\n",
        "new_data = np.array([[130.0, 15.2, 160.0, 3.5, 25.0, 110.8, 40000.0, 65.0,\n",
        "                      95.0, 98.0, 60.0, 75.0, 150.0, 1400.0, 4.0]])\n",
        " # 15 values\n",
        "\n",
        "# Scale the new input data\n",
        "new_data_scaled = loaded_scaler.transform(new_data)\n",
        "\n",
        "# Predict the class for the new input\n",
        "prediction = loaded_model.predict(new_data_scaled)\n",
        "print(\"\\nPredicted Class for new input:\", prediction)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bh3B65cQTcs-",
        "outputId": "ddc09ab2-84fd-4ca3-8330-d6da894f3df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'subsample': 0.8, 'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 0.6}\n",
            "\n",
            "Confusion Matrix:\n",
            "[[3 1 0 0]\n",
            " [0 3 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 2]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.75      0.86         4\n",
            "           1       0.75      1.00      0.86         3\n",
            "           3       1.00      1.00      1.00         2\n",
            "           4       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.91        11\n",
            "   macro avg       0.94      0.94      0.93        11\n",
            "weighted avg       0.93      0.91      0.91        11\n",
            "\n",
            "\n",
            "Accuracy Score: 0.9090909090909091\n",
            "\n",
            "Predicted Class for new input: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check feature names in the dataset to verify inclusion\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K0QPw8mVBxF",
        "outputId": "fb6c2bf7-ff20-4a24-c532-690b80809606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Latitude', 'Longitude', 'TB Incidence', 'Diabetes ',\n",
            "       'Malaria Incidence', 'HIV/AIDS', 'IMR', 'Vaccination ', 'Income (INR)',\n",
            "       'Employment Rate', 'Education ', 'Housing', 'Urbanization ', 'AQI',\n",
            "       'Annual Rainfall (mm)', 'Target (Healthcare Access)'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model and scaler\n",
        "loaded_model = joblib.load('xgb_best_model.pkl')\n",
        "loaded_scaler = joblib.load('xgb_scaler.pkl')\n",
        "\n",
        "# List of feature names including latitude and longitude\n",
        "feature_col_names = [\n",
        "    \"Latitude\", \"Longitude\", \"TB Incidence\", \"Diabetes\",\n",
        "    \"Malaria Incidence\", \"HIV/AIDS\", \"IMR\", \"Vaccination\",\n",
        "    \"Income (INR)\", \"Employment Rate\", \"Education\", \"Housing\",\n",
        "    \"Urbanization\", \"AQI\", \"Annual Rainfall (mm)\"\n",
        "]\n",
        "\n",
        "# Collect user input for all features\n",
        "user_input = []\n",
        "for feature_name in feature_col_names:\n",
        "    value = float(input(f\"Enter value for {feature_name}: \"))\n",
        "    user_input.append(value)\n",
        "\n",
        "# Convert the user input to a numpy array and reshape it\n",
        "user_input_array = np.array(user_input).reshape(1, -1)\n",
        "\n",
        "# Scale the user input\n",
        "user_input_scaled = loaded_scaler.transform(user_input_array)\n",
        "\n",
        "# Predict the class using the loaded model\n",
        "prediction = loaded_model.predict(user_input_scaled)\n",
        "\n",
        "# Output the prediction result based on the class\n",
        "if prediction[0] == 0:\n",
        "    print(\"The model predicts: VERY LOW ACCESS\")\n",
        "elif prediction[0] == 1:\n",
        "    print(\"The model predicts: LOW ACCESS\")\n",
        "elif prediction[0] == 2:\n",
        "    print(\"The model predicts: MODERATE ACCESS\")\n",
        "elif prediction[0] == 3:\n",
        "    print(\"The model predicts: HIGH ACCESS\")\n",
        "elif prediction[0] == 4:\n",
        "    print(\"The model predicts: VERY HIGH ACCESS\")\n",
        "else:\n",
        "    print(\"Invalid prediction result.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biQ-AxE6VW3E",
        "outputId": "63cca92c-aa25-40a6-f180-77aba59558fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter value for Latitude: 15.36\n",
            "Enter value for Longitude: 80.05\n",
            "Enter value for TB Incidence: 115\n",
            "Enter value for Diabetes: 11.9\n",
            "Enter value for Malaria Incidence: 125\n",
            "Enter value for HIV/AIDS: 3.9\n",
            "Enter value for IMR: 27\n",
            "Enter value for Vaccination: 88\n",
            "Enter value for Income (INR): 41000\n",
            "Enter value for Employment Rate: 59.5\n",
            "Enter value for Education: 76\n",
            "Enter value for Housing: 72\n",
            "Enter value for Urbanization: 45\n",
            "Enter value for AQI: 93\n",
            "Enter value for Annual Rainfall (mm): 1000\n",
            "The model predicts: VERY LOW ACCESS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}